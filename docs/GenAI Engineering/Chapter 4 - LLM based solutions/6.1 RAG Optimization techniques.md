# RAG Optimization techniques (WIP)

## Parser optimization techniques

## Pre-retrieval work

### Metadata

Metadata is probably one of the most underrated element in improving a RAG system.
It consists in adding metadata and index those for your documents. It is important because it brings context on:

- dates, time, version of your document that can be confusing for your LLM
- outer context: team origination, objectives, business logic
- summarizing the key elements of the document with specific keywords to have a faster multi-step retriever (using filtering)
- etc...

### Chunking strategies

See docs/Chapter 6 - LLM based solutions/Chunking strategies.md for details on chunking.

### Fine tune embedding models

## During retriever phase

### Query routing

Routing a query gives the option to have multiple options to handle this query.
You can have multiple LLMs with each specifically suited for a request type, you can have different tooling or wish for having deterministic answer in some cases.
The simplest example is also a best practice: you need to understand if the user query is within the context of your solution.
If not, you may want to answer a specified text or redirect to specific content.
This can be done within a system prompt or an expert LLM.

In a more complex world, you can have an AI agents that can efficiently route your query reasoning on the best option.
This might significantly increase your latency.

### Query re-writing

Although LLMs "understand" NLP, very often user query is not written in an ideal way for an LLM.
It can miss some context, have relevant typo issues leading to semantic errors.
Query rewriting transforms the original user query into a more effective version for information retrieval. Instead of just doing retrieve-then-read, applications now do a rewrite-retrieve-read approach. This technique restructures oddly written questions so they can be better understood by the system, removes irrelevant context, introduces common keywords that improve matching with correct context, and can split complex questions into simpler sub-questions.
Concretely, this step restructure unclear questions, remove useless or inefficient context and introduces common terminology that can increase the likelihood of matching documents.

### Query expansion

While query rewriting, enables more semantic meaning between the user and the LLM/embedding, expansion generates multiple queries from a single input.
It can significantly enhance the retriever phase by expanding the context or diversify the search to neighbouring meaning.
It's helpful when the document informations are dense and complex.

However, it may bring latency overhead if used intensively.

### Query decomposition

Sometimes the user query has multiple sub-queries in it or is quite complex to dig into the VectorDB directly.
That's where query decomposition comes in: it breaks the original query into simpler ones that may require multiple sources.

### Metadata filtering

### Hybrid search

### Graph DBs

## Post retriever

- Use prompt compression techniques.
- Filter out irrelevant chunks to avoid adding noise to the augmented prompt
- Use re-ranker
